{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elaboração de um novo modelo de classificação com base nas informações de usuários avaliados pelo INCT-DD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carrega as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, matthews_corrcoef, mean_squared_error, r2_score, mean_absolute_percentage_error, max_error, explained_variance_score, median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "import math\n",
    "import statistics\n",
    "import datetime\n",
    "import pytz\n",
    "import pickle\n",
    "## NLTK (biblioteca para processamento de linguagem natural)\n",
    "import nltk\n",
    "from nltk.stem.rslp import RSLPStemmer ##http://www.nltk.org/howto/portuguese_en.html\n",
    "\n",
    "#O primeiro uso exige obter os pacotes adicionais da biblioteca descomentando as linhas a seguir\n",
    "#Instala os pacotes de termos do nltk (apenas na primeira vez)\n",
    "#nltk.download()\n",
    "#nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O novo modelo de classificação de bots foi construído com base nos usuários manualmente avaliados pelo INCT-DD**\n",
    "\n",
    "Essa escolha foi tomada considerando que esse conjunto de dados é o melhor que se possui quanto à real possibilidade de um usuário do Twitter ser um bot, não existindo bases de avaliação dentro da realidade brasileira (especialmente quanto ao português), bem como atualizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca os dados dos usuários avaliados\n",
    "datafile_users = \"data/sample2/inct_users.csv\"\n",
    "df_users = pd.read_csv(datafile_users, header = 0)\n",
    "\n",
    "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
    "df_users = df_users.fillna(0)\n",
    "print(len(df_users))\n",
    "#Apresenta o total de usuários avaliados\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No novo modelos são consideradas apenas as informações associadas como \"É bot?\" de respotas \"Sim\" ou \"Não\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca a classificação do INCT-DD\n",
    "datafile_handles = \"data/sample1/handles_inct.csv\" #A classificação é a mesma da sample1\n",
    "df_handles = pd.read_csv(datafile_handles, header = 0)\n",
    "print(len(df_handles))\n",
    "df_handles['É Bot?'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As mais recentes postagens dos usuários foram consideradas como um atributo do modelo**\n",
    "\n",
    "Para a classificação dos usuários, o novo modelo inclui atributos relacionados com as postagens dos usuários, na tentativa de extrair informação mais atualizada e dinâmica de sua atuação. Entretanto, os textos das postagens foram utilizados unificando seus conteúdos e extraindo informações representativas, tais como os termos mais recorrentemente utilizados, diferença no tempo das postagens e repostagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recupera os últimos twittes\n",
    "datafile_timeline = \"data/sample2/inct_timelines.csv\"\n",
    "df_timeline = pd.read_csv(datafile_timeline, header = 0)\n",
    "print(len(df_timeline))\n",
    "df_timeline.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica um pré-processamento nos dados para unificar a informação da postagens se tratar de um retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifica os formatos existentes\n",
    "df_timeline['tweet_is_retweet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeline['retweet_tratado'] = df_timeline['tweet_is_retweet'].apply(lambda x: \"sim\" if (x == 'True' or x == True) else \"não\")\n",
    "df_timeline['retweet_tratado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessário reverificar no texto do tweet por RT @, pois o campo tweet_is_retweet falha em algumas situações não identificadas\n",
    "#Parecem ser os RT com comentários adicionais\n",
    "#for tweet in df_timeline['retweet_tratado', 'tweet_text']:\n",
    "#    if tweet['retweet_tratado'] == 'não':\n",
    "#        if tweet['tweet_text'].find(\"RT @\") != -1:\n",
    "#            tweet['retweet_tratado'] = 'sim'\n",
    "#len(df_timeline)\n",
    "#for i in range(len(df_timeline)):\n",
    "#    if df_timeline.iloc[i]['retweet_tratado'] == 'não':\n",
    "#        if df_timeline.iloc[i]['tweet_text'].find(\"RT @\") != -1:\n",
    "#            df_timeline.iloc[i]['retweet_tratado']  = 'sim'\n",
    "df_timeline['tweet_com_rt_tratado'] = df_timeline['tweet_text'].apply(lambda x: \"sim\" if x.find(\"RT @\") != -1 else \"não\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combina em uma única coluna as informações de retweets e tweets com RT comentados\n",
    "def reune_rt(retweet,rt):\n",
    "    if retweet == 'sim' or rt == 'sim':\n",
    "        return 'sim'\n",
    "    else:\n",
    "        return 'não'\n",
    "\n",
    "df_timeline['retweet_e_tweet_com_rt_tratado'] = df_timeline.apply(lambda x: reune_rt(x.retweet_tratado, x.tweet_com_rt_tratado), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeline[df_timeline[\"retweet_e_tweet_com_rt_tratado\"] == 'sim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrai a diferença em segundos entre as postagens do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Incluir uma dedida da distancia temporal entre twittes (mediana e mínimo)\n",
    "df_handles['Tempo mediano'] = np.array(len(df_handles))\n",
    "df_handles['Tempo menor']   = np.array(len(df_handles))\n",
    "iuser = 0\n",
    "for user in df_handles['handle']:\n",
    "    df_temp = df_timeline[df_timeline['tweet_author'] == user]\n",
    "    itweet = 0\n",
    "    menor = 100000\n",
    "    difs = list()\n",
    "    tweet_date_prev = None\n",
    "    for tweet in df_temp['tweet_created_at']:\n",
    "        tweet_date = pd.to_datetime(pd.to_datetime(tweet).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "        if itweet > 0:\n",
    "            dif = (tweet_date_prev - tweet_date).seconds\n",
    "            if dif < menor:\n",
    "                menor = dif\n",
    "            difs.append(dif)\n",
    "        else:\n",
    "            tweet_date_prev = tweet_date\n",
    "        tweet_date_prev = tweet_date\n",
    "        itweet += 1\n",
    "    if len(difs) > 0:\n",
    "        mediana = statistics.median(difs)\n",
    "    else:\n",
    "        mediana = 1000\n",
    "    print(user + ' - ' + str(menor) + ' - ' + str(mediana)+'\\n')\n",
    "    df_handles['Tempo mediano'][iuser] = mediana\n",
    "    df_handles['Tempo menor'][iuser]   = menor\n",
    "    iuser += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os dados inicialmente tratados são reunidos com a classificação dada pelo INCT-DD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune os dados do usuário com a classificação\n",
    "df_result_merge = pd.merge(df_handles, df_users, on=['handle'])\n",
    "print(len(df_result_merge))\n",
    "df_result_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os dados das postagens foram reunidos para a extração de informações representativas**\n",
    "\n",
    "Para viabilizar o treinamento do modelo, os dados por postagens foram convertidos em conjuntos por usuário (autor do tweet, e a representação foi dada por informações sumarizadas ou probabilísticas, por exemplo, as hashtags mais utilizadas ou o percentual de postagens realizadas a partir do Android, iPhone ou Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune todos os tweets de um mesmo autor em um único texto, separando apenas por vírgula\n",
    "df_result_text = df_timeline.groupby('tweet_author').agg({'tweet_text':lambda col: ', '.join(col)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune todos as hashtags utilizadas por um mesmo autor em um único texto, separando apenas por vírgula\n",
    "df_result_hashtags = df_timeline.groupby('tweet_author').agg({'tweet_hashtags':lambda col: ', '.join(col)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune a informação de fonte de todos os tweets de um mesmo autor em um único texto, separando apenas por vírgula\n",
    "df_result_source = df_timeline.groupby('tweet_author').agg({'tweet_source':lambda col: ', '.join(col)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune as informações de twettes que são retweets\n",
    "df_result_retweet = df_timeline.groupby('tweet_author').agg({'retweet_tratado':lambda col: ', '.join(col)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune as informações de twettes com RT\n",
    "df_result_tweet_com_rt = df_timeline.groupby('tweet_author').agg({'tweet_com_rt_tratado':lambda col: ', '.join(col)}).reset_index()\n",
    "df_result_tweet_com_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune as informações da junção de retweets e tweets com rt\n",
    "df_result_retweet_e_tweet_com_rt = df_timeline.groupby('tweet_author').agg({'retweet_e_tweet_com_rt_tratado':lambda col: ', '.join(col)}).reset_index()\n",
    "df_result_retweet_e_tweet_com_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune os dados (merge) do usuários, suas avaliações com texto dos tweets, as hashtags, as fontes e os retweets\n",
    "df_result_merge = pd.merge(df_handles, df_users, on=['handle'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_text, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_hashtags, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_source, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_retweet, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_tweet_com_rt, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_retweet_e_tweet_com_rt, left_on=['handle'], right_on=['tweet_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exibe parte dos resultados da junção (nem todos os usuários ainda estão ativos e número de amostras diminui)\n",
    "print(len(df_result_merge))\n",
    "df_result_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A classificação dos usuários foi padronizada para 0 - Não Bot e 1 - Bot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padroniza a saída da classificação do INCT-DD para bot e monta o conjunto Y\n",
    "df = df_result_merge\n",
    "y = df['É Bot?'].apply(lambda x: 1 if (x == 'Sim' or x == 'sim') else 0)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Seleciona as colunas para o conjunto X\n",
    "#feature_cols = ['tweet_text'] #,'tweet_source','tweet_hashtags'\n",
    "#x = df['tweet_text']\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** [Classficando apenas pelo texto dos Twittes (NLTK)] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prepara o conjunto de dados para treinamento e teste\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Método para vetorizar e contabilizar os termos\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "class StemmedCountVectorizerRSLPS(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizerRSLPS, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizerRSLPS(stop_words=nltk.corpus.stopwords.words('portuguese'))\n",
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pipeline para extrair as informaçoes e classificar com base no texto (pode ser usado ANN ou MNB [MultinomialNB(fit_prior=False)])\n",
    "#text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('mnb', MLPClassifier(random_state=1, max_iter=600, activation='relu',solver='adam')),\n",
    "#])\n",
    "#text_mnb_stemmed = text_mnb_stemmed.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_mnb_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Avalia a classificação\n",
    "#predicted_mnb_stemmed = text_mnb_stemmed.predict(x_test)\n",
    "#np.mean(predicted_mnb_stemmed == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os atributos do treinamentos envolvem diversos fatores**\n",
    "\n",
    "Uma das etapas mais critícas da modelagem é a definição dos atributos que representam o cenário real, nesse sentido foram incluídas o máximo de variáveis que pudessem representar um usuário e suas atividades na rede, desde o tamanho do login escolhido até o tempo mínimo entre suas postagens. Na sequência são realizadas as atividades de extração, tratamento e junção dessas informações como atributos do conjunto de treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #df é o conjunto completo de dados, já com os twittes-hashtags-sources-retweets em campos únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De todo os conjuntos de informações disponíveis não foram selecionados aquelas que não poderiam ser automaticamente extraídos dos perfis e atividades dos usuários na rede. Portanto, as classificações como \"comportamento agressivo?\", \"Parece só Retweetar?\", entre outras, não foram incluídos no conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['followers_count', 'friends_count', 'Tempo mediano', 'Tempo menor']\n",
    "x = df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converte os testos em frequências\n",
    "#st = stemmed_count_vect.fit_transform((df['tweet_text']))\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#x_tfidf = tfidf_transformer.fit_transform(st)\n",
    "#x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inclui as frequências no conjunto x\n",
    "#x_tfidf.shape\n",
    "#x.join(pd.DataFrame(x_tfidf.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['tweet_hashtags'][7].replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\"))\n",
    "len(df['tweet_hashtags'][7].split(\", [\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inclui os quantitativos de hashtages utilizadas (e a mediana por postagem)\n",
    "\n",
    "qtd_hashtags = df['tweet_hashtags'].apply(lambda x: len(x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\")))\n",
    "x['Quantidade hashtags'] = np.array(list(qtd_hashtags))\n",
    "qtd_hashtags_media = df['tweet_hashtags'].apply(lambda x: len(x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\"))/len(x.split(\", [\")))\n",
    "x['Quantidade hashtags media'] = np.array(list(qtd_hashtags_media))\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inclui o número de dígitos no nome\n",
    "username_digitos = df['handle'].apply(lambda x: sum(c.isdigit() for c in str(x)) ) \n",
    "x['Digitos no username'] = np.array(list(username_digitos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O tamanho do nome e do login\n",
    "tam_username = df['handle'].apply(lambda x: len(str(x)))\n",
    "tam_nome = df['name'].apply(lambda x: len(str(x)))\n",
    "x['Tamanho do username'] = np.array(list(tam_username))\n",
    "x['Tamanho do nome'] = np.array(list(tam_nome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fonte do tweet foi considera importante informação, considerando que automações de postagens possam ser facilitadas a partir da versão Web ou que possa existir algum padrão no uso das diferentes fontes. Sendo assim, forneceu-se ao métodos a informação percentual da origem das postagens do mesmo usuário, seja Android, iPhone ou Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula a quantidade de twittes por fontes\n",
    "fonte_android = df['tweet_source'].apply(lambda x: str(x).count('Twitter for Android') )\n",
    "fonte_iphone = df['tweet_source'].apply(lambda x: str(x).count('Twitter for iPhone') )\n",
    "fonte_web = df['tweet_source'].apply(lambda x: str(x).count('Twitter Web App') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonte_soma = fonte_android + fonte_iphone + fonte_web\n",
    "fonte_soma = fonte_soma.apply(lambda x: 1 if x <= 0 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula o percentual por usuário\n",
    "fonte_android = fonte_android/fonte_soma\n",
    "fonte_iphone = fonte_iphone/fonte_soma\n",
    "fonte_web = fonte_web/fonte_soma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Fonte de Android'] = np.array(list(fonte_android))\n",
    "x['Fonte de iPhone'] = np.array(list(fonte_iphone))\n",
    "x['Fonte de Web'] = np.array(list(fonte_web))\n",
    "x = x.fillna(0)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação geral das diferentes fontes\n",
    "x['Fonte de Android'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Fonte de iPhone'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Fonte de Web'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inclui a informação do retweet\n",
    "df['retweet_tratado'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_tratado = df['retweet_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
    "x['retweet_tratado_media'] = np.array(list(retweet_tratado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_com_rt = df['tweet_com_rt_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
    "x['tweet_com_rt_tratado_media'] = np.array(list(tweet_com_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_e_tweet_com_rt = df['retweet_e_tweet_com_rt_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
    "x['retweet_e_tweet_com_rt_tratado_media'] = np.array(list(retweet_e_tweet_com_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inclui os textos dos twittes (NLTK)\n",
    "#st = stemmed_count_vect.fit_transform((df['tweet_text']))\n",
    "#tfidf_transformer = TfidfTransformer()\n",
    "#x_tfidf = tfidf_transformer.fit_transform(st)\n",
    "#x_tfidf\n",
    "#x_novo = x.join(pd.DataFrame(x_tfidf.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Com o primeiro conjunto de atributos formado é possível separar o conjunto de dados em treinamento e teste para a elaboração do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um modelo de classificação para o conjunto completo\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_novo, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
    "classifier = classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Seleciona os atributos mais \"importantes\"\n",
    "#x_new = SelectKBest(chi2, k=20).fit_transform(x_novo, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
    "classifier = classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "mean = np.mean(y_pred == y_test)\n",
    "balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificação com RNA\n",
    "classifier = MLPClassifier(max_iter=1200, random_state=1, activation='tanh', solver='adam') #activation: logistic, relu, tanh, identity | solver: lbfgs, sgd, adam\n",
    "classifier = classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "mean = np.mean(y_pred == y_test)\n",
    "balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informações de trend topics**\n",
    "\n",
    "Outra informação que se mostrou de relevância ao longo do trabalho de modelagem foi a relação das postagens de bots com as menções e hashtags listadas nos mais atuais 'trend topics', ou seja, o aparente uso de termos altamente utilizados no momento para possivelmente alavancar a visibilidade da postagem.\n",
    "\n",
    "Para averiguar essa possibilidade, um sistema de monitoramento dos tópicos mais mencionados foi criado e cada postagem coletada do usuário foi confrontado com os 'trend topics' do período mais próximo. Esse confrontamento gerou um percentual de uso desses tópicos nas postagens dos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busca os dados de todas as trending topics recuperadas\n",
    "datafile_trends = \"data/sample2/trends_dataclips_qijpjdyxutqsnrteglrjtwjhdjja.csv\"\n",
    "df_trends = pd.read_csv(datafile_trends, header = 0)\n",
    "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
    "df_trends = df_trends.fillna(0)\n",
    "print(len(df_trends))\n",
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre os passos de tratamentos dos dados das \"trend topics\" está o ajuste dos padrões de data e hora dos registros, tanto dos tópicos monitorados quanto dos próprios tweets.\n",
    "A seguir são extraídas as datas dos tweets no formato yyyy-mm-dd, dentro da conversão nos próximos trechos foi também necessário ajustar o \"timezone\" desses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inclui um percentual de trending topics utilizado por tweet\n",
    "#Para tweet, busca pelos trending topics imediatamente anteriores\n",
    "df_timeline['Numero de trendings'] = np.array(len(df_timeline))\n",
    "df_timeline['Numero de trendings'] = 0\n",
    "df_trends['Trend Date Time Convertido'] = np.array(len(df_trends))\n",
    "\n",
    "itrend = 0\n",
    "for x in df_trends['trend_date_time']:\n",
    "    df_trends['Trend Date Time Convertido'][itrend] = pd.to_datetime(x).strftime(\"%Y-%m-%d\")\n",
    "    itrend += 1\n",
    "\n",
    "df_trends.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O relacionamento dos trends e dos tweets foi realizado percorrendo todos os trends armazenados para cada tweet em data anterior ao do tweet e, para cada trend nessa condição, verificou-se no texto do tweet a presença de trendings. Caso esteja presente acumulou-se essa ocorrência, finalizando com a ocorrência de uso de uma trend por cada tweet.\n",
    "Este trecho demanda de melhorias em desempenho e na inclusão de restrições que reduzam o tempo de ocorrência da trend para mais próximo do tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itweet = 0\n",
    "for tweet in df_timeline['tweet_created_at']:\n",
    "    tweet_date = pd.to_datetime(pd.to_datetime(tweet).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    df_temp = df_trends[df_trends['Trend Date Time Convertido'] == tweet_date.strftime(\"%Y-%m-%d\")] \n",
    "        \n",
    "    itrend = 0\n",
    "    for trend in df_temp['Trend Date Time Convertido']:\n",
    "        trend_date = pd.to_datetime(pd.to_datetime(trend).strftime(\"%Y-%m-%d\"))\n",
    "        if trend_date <= tweet_date.tz_convert(None):\n",
    "            if df_timeline['tweet_text'][itweet].find(df_trends['trend'][itrend]) != -1: \n",
    "                df_timeline['Numero de trendings'][itweet] = df_timeline['Numero de trendings'][itweet] + 1\n",
    "        itrend += 1\n",
    "    print(itweet)    \n",
    "    itweet += 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tweet foi armazenados o número de trend topics encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeline[df_timeline['Numero de trendings'] > 0].describe()\n",
    "df_timeline['Numero de trendings'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As quantidades de trendings utilizadas em cada tweet foram agrupados por autor (usuário), assim foram incluídos na base de treinamento o número de trendings utilizadas, a média de trendings por tweet desse autor e o número máximo de trendings usado em um mesmo tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reune as informações de trends nos tweets por author\n",
    "df_result_trend = df_timeline.groupby('tweet_author').agg({'Numero de trendings':lambda col: sum(col)/len(col)}).reset_index()\n",
    "df_result_trend_max = df_timeline.groupby('tweet_author').agg({'Numero de trendings':lambda col: max(col)}).reset_index()\n",
    "df_result_trend['trends_media'] = df_result_trend['Numero de trendings']\n",
    "df_result_trend_max['trends_max'] = df_result_trend_max['Numero de trendings']\n",
    "df_result_trend_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_handles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_unique = df_trends.trend.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores referentes aos trendings do usuário são reunidos (\"merged\") com os dados gerais do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_merge = pd.merge(df_result_merge,df_result_trend, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge = pd.merge(df_result_merge,df_result_trend_max, left_on=['handle'], right_on=['tweet_author'])\n",
    "df_result_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result_merge_trend = df_result_merge\n",
    "df_result_merge['qtdtrends'] = np.array(list(tam_username))\n",
    "\n",
    "ttemp = 0\n",
    "iuser = 0\n",
    "for user in df_result_merge.tweet_text:\n",
    "    for trend in trends_unique:\n",
    "        if user.find(trend) != -1:\n",
    "            ttemp = ttemp + 1\n",
    "    print(str(ttemp) + \" - \" + str(iuser) + \" | \" + str((iuser/len(df_result_merge.tweet_text))*100) + \"%\")\n",
    "    df_result_merge['qtdtrends'][iuser] = ttemp\n",
    "    iuser = iuser + 1\n",
    "    ttemp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo_trend = x_novo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim os dados do monitoramento das trendings são incluídos na base de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo_trend['qtdtrends'] = df_result_merge['qtdtrends']\n",
    "x_novo_trend['trends_media'] = df_result_merge['trends_media']\n",
    "x_novo_trend['trends_max'] = df_result_merge['trends_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_novo_trend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conjuntos de treinamento e teste**\n",
    "\n",
    "Os dados reunidos para geração dos modelos são, então, separados em dados de treinamento e teste para a aplicação dos métodos de aprendizagem de máquina - em especial Random Florest, Redes neuronais artificiais e Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_novo_trend, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
    "classifier = classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "mean = np.mean(y_pred == y_test)\n",
    "balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
    "print(\"Score: \" + str(classifier.score(x_test, y_test)))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=1)\n",
    "classifier = classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "mean = np.mean(y_pred == y_test)\n",
    "balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
    "print(\"Score: \" + str(classifier.score(x_test, y_test)))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = classifier.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 6))\n",
    "ax.barh(range(len(importances)), importances[indices])\n",
    "ax.set_yticks(range(len(importances)))\n",
    "_ = ax.set_yticklabels(np.array(x_novo_trend.columns)[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados**\n",
    "\n",
    "Os resultados ainda demandam de maior avaliação, especialmente com a variação da semente aleatória para os cortes do conjunto de treinamento e para a aplicação dos métodos. Ainda nesse sentido, demanda-se ainda da seleção de modelos baseada na otimização dos hiperparâmetros dos métodos aplicados.\n",
    "\n",
    "Mesmo com essas demandas, observa-se uma acurácia aproximada de 74% para os métodos (e aproximadamente 70% ao considerar-se o desbalanceamento da base). Valor considerado bom, dado o complexo cenário tratado. \n",
    "\n",
    "Importante ponto a ser destacado que o valor da acurácia baseia-se também em um ponto de corte da consistência da classificação, a qual pode variar en 0.0 e 1.0, valores que atrelam-se à probabilidade da classificação, em que por padrão adota-se o corte em 0.5, apesar da aplicação pode gerar um intervalo mais restrito, deslocando a média/mediana das predições. Dito isso e considerando que não deva ser utilizado apenas o corte \"bruto\" de bot ou não bot, a associação dessa probabilidade permite melhor compreensão do \"risco\" do usuário ser efetivamente um bot, bem como permite um deslocamento do rigor dessa classificação. \n",
    "\n",
    "Os trechos a seguir avaliam a acurácia considerando a mediana das predições como corte, bem como a comparação dos valores preditos nos grupos de usuários previamente (manualmente) classificados como bot ou não, no qual verifica-se uma clara separação dos valores preditos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_new_trend = SelectKBest(chi2, k=10).fit_transform(x_novo_trend, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x_new_trend, y, test_size=0.3, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
    "#classifier = classifier.fit(x_train,y_train)\n",
    "#y_pred = classifier.predict(x_test)\n",
    "#mean = np.mean(y_pred == y_test)\n",
    "#balanced = balanced_accuracy_score(y_test, y_pred)\n",
    "#print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
    "#confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_new_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba = classifier.predict_proba(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(classifier.predict_proba(x_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6\n",
    "predicted = (classifier.predict_proba(x_test)[:,1] >= threshold).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_geral = x_test\n",
    "dtf = [x_test, x_train]\n",
    "x_test_geral = pd.concat(dtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_test_geral))\n",
    "y_test_temp = y_test\n",
    "y_test_temp.reset_index(drop=True, inplace=True)\n",
    "y_test_temp[y_test_temp == 1].index\n",
    "res_geral = classifier.predict_proba(x_test_geral)[y_test_temp.index,1]\n",
    "res_sim = classifier.predict_proba(x_test_geral)[y_test_temp[y_test_temp == 1].index,1]\n",
    "res_nao = classifier.predict_proba(x_test_geral)[y_test_temp[y_test_temp == 0].index,1]\n",
    "\n",
    "np.median(res_sim)\n",
    "np.median(res_nao)\n",
    "bplots = plt.boxplot([res_geral, res_nao, res_sim],  vert = 1, patch_artist = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Não\": res_nao}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Sim\": res_sim}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparação com as predições do Botometer**\n",
    "\n",
    "Visando a avaliar a qualidade da classificação dos modelos gerados, os mesmos usuários passaram pela avaliação da ferramenta Botometer, já bem conhecida e amplamente utilizada (apesar de sua aplicação com enfoque nas publicações em Inglês)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lê os dados da aplicação do botometer\n",
    "#Busca os dados dos usuários avaliados\n",
    "datafile_botometer = \"data/handles_inct.csv\"\n",
    "df_botometer = pd.read_csv(datafile_botometer, header = 0)\n",
    "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
    "df_botometer = df_botometer.fillna(0)\n",
    "print(len(df_botometer))\n",
    "df_botometer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avalia os resultados do botometer\n",
    "a = len(df_botometer['analise_botometer'])\n",
    "b = len(df_botometer[(df_botometer['É Bot?'] == 'não') | (df_botometer['É Bot?'] == 'Não')]['analise_botometer'])\n",
    "c = len(df_botometer[(df_botometer['É Bot?'] == 'sim') | (df_botometer['É Bot?'] == 'Sim')]['analise_botometer'])\n",
    "print(\" \" + str(a) + \" = \" + str(b) + \" + \" + str(c))\n",
    "botometer_geral = df_botometer['analise_botometer']\n",
    "botometer_nao   = df_botometer[(df_botometer['É Bot?'] == 'não') | (df_botometer['É Bot?'] == 'Não')]['analise_botometer']\n",
    "botometer_sim   = df_botometer[(df_botometer['É Bot?'] == 'sim') | (df_botometer['É Bot?'] == 'Sim')]['analise_botometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(20, 10)) #(11, 6)\n",
    "bplots = plt.boxplot([botometer_geral/5, botometer_nao/5, botometer_sim/5, res_geral, res_nao, res_sim],  vert = 1, patch_artist = False)\n",
    "colors = ['blue', 'green', 'red', 'lightblue', 'lightgreen', 'pink']\n",
    "c = 0\n",
    "for i, bplot in enumerate(bplots['boxes']):\n",
    "    bplot.set(color=colors[c], linewidth=3)\n",
    "    c += 1\n",
    "    \n",
    "colorss = ['blue','blue', 'green', 'green', 'red', 'red', 'lightblue', 'lightblue', 'lightgreen', 'lightgreen', 'pink', 'pink' ]    \n",
    "c3 = 0\n",
    "for cap in bplots['caps']:\n",
    "    cap.set(color=colorss[c3], linewidth=3)\n",
    "    c3 +=1\n",
    "\n",
    "plt.title(\"Boxplot da avaliação do Botometer e do novo modelo Pegabot para os dados avaiados no INCT-DD\", loc=\"center\", fontsize=18)\n",
    "plt.xlabel(\"Agrupados por: (1) Botometer Geral; (2) Botometer apenas considerados não bots; (3) Botometer apenas considerados bots; (4) Novo Pegabot Geral; (5) Novo Pegabot apenas considerados não bots; (6) Novo Pegabot apenas considerados bots\")\n",
    "plt.ylabel(\"Avaliação do Botometer\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.kruskal(botometer_geral,  botometer_nao,botometer_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.kruskal(res_geral,  res_nao,res_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
